---
updateTime: '2025-12-21 18:26'
tags: 架构
---
> ks直播实习 二面评价在做系统设计考虑得不够完美(假设订单量激增10倍怎么保证履约效率？)，特写此篇记录一下，我对整体个系统设计的理解
## 领域建模
> 从需求出发，划分领域模型，再划分为多个子领域，比如实习里的对接第三方的订单就是我的核心子领域
> 
- 明确核心业务需求
  - 履约分为 **仓储**、**物流**、**订单**等等。。
> 我的订单子域的 第三方订单对接系统的核心需求包括：第三方订单接入与解析、订单信息存储与同步、订单状态回调通知、异常订单处理、与平台内部库存 / ERP / 物流系统联动。基于这些需求，先提炼出系统的核心领域模型。
- 核心领域模型 与 子领域划分
  - 物流
    - 物流分流
    - 物流轨迹
    - 账单对账
  - 仓储
    - 拣货
    - 分拣
    - 上架
    - 库存
    - 采购/预售
  - 订单
    - 第三方渠道订单
    - 系统内订单
    - 订单明细
## 梳理业务架构
> 划分好领域模型后，针对某个领域理清有哪些 **业务场景** ->  系统用例(用例图) ->  数据架构(类图、ER图) -> 业务流程(时序图)
> 即c4 model(context、container、component、code)
## 根据业务属性预估流量，峰值和低峰值
> - 基础数据：假设日均订单 2 万单，第三方平台 3 个（A 平台占 60%、B/C 各占 20%）。
> - 峰值计算：促销日（如双 11）峰值是日均 3-5 倍，即 6-10 万单 / 天；瞬时峰值按 “日峰值 / 86400 秒 ×10 倍（秒杀突发）”，约 7-12 单 / 秒（高并发场景可按 10-20 倍放大）。**假设两分钟一次扫表，需要约处理1200单**。如果要求系统**2分钟内必须完成履约**，如果部署 5 个服务实例，每个实例 10 个线程，总并行数 50，同步情况下 2 分钟内最多处理 50 单。
> - 低峰值：凌晨 1-6 点，订单量为日均 10%，约 1000 单 / 天，瞬时 0.01-0.05 单 / 秒。

## 设计技术方案
  - mysql是否要分库分表
    - 判断依据：按日均 10 万单计算，年订单量约 3600 万单，如果系统要使用10年，总订单量就会达到3亿单。假设一张表存储1000万数据，就需要30张表(**向上取到2^n就是64张表**)
  - redis多少个主从实例
  - 要不要MQ
    - 根据峰值计算，如果同步情况下，**2分钟内只能处理50个订单**，远远不满足峰值1200单，所以必须**异步处理**。订单拆单，订单预创建，风控检验，推送ERP任务 解耦

## 做好数据埋点、监控
-  数据埋点：聚焦核心链路
    -  **业务埋点**：订单接收成功率、转换失败率、第三方接口响应耗时。
    -  **技术埋点**：接口 QPS、错误码分布、MQ 消息堆积量、Redis 缓存命中率。
    -  埋点工具：用 Arms/skywalking 做链路追踪，Prometheus 采集指标，云服务/ELK 存储日志。
- 监控告警：分层设置阈值
    -  核心接口：履约时效 > 2min 告警，错误率 > 0.1% 紧急告警。
    -  中间件：MQ 堆积量 > 1 万条告警，Redis 主从同步延迟 > 1s 告警，MySQL 连接数 > 80% 告警。
    -  告警渠道：短信 + 企业微信 / 飞书，按严重级别分级推送。

## 保护核心接口，保证系统稳定性
核心接口（如订单接入接口、回调接口）的稳定性直接影响业务，需通过多重手段防护。
- 熔断降级
当**第三方渠道接口异常率**超过阈值时，触发熔断，暂时停止调用该渠道接口，把订单落到重发表里，待渠道恢复后自动熔断恢复。
- 幂等性与容错设计
    -  **幂等性**保障：订单接入接口以第三方渠道订单号为唯一标识，利用mysql**唯一索引保证幂等**；下单和扣库存采用**流水表保证TCC空回滚和事务悬挂**。
    -  容错处理：核心接口采用重试机制，如调用第三方接口超时，重试 2 次（间隔 1 秒）；数据库操作失败时，通过本地事务回滚避免脏数据。
    -  一致性保证：引入**分布式事务** 和 **对账**保证数据最终一致性
### 最终一致性兜底(对账)
> 在跨系统之间的数据写入场景下，上下游系统极有可能因为**网络超时/抖动、或写本地DB与调外部接口不能同时成功**等原因，而出现数据不一致的问题，因此需要有及时发现不一致问题、并自动修复的能力。<br>
> 注意：这里提的对账**不特指资金对账，而是跨系统的字段对账**
#### 对账的指标
- **完备性**：确保所有字段都有对账
- **时效性**：越高越好，秒级 > 分钟级 > 小时级 > 天级
- **自动修复**：对账发现不一致后自动修复，然后再次对账，确保修复后是最终一致的，形成闭环
#### 实时对账（秒级到分钟级对账）
实时对账可以尽快发现不一致，一般由数据**写入方发起**对账，数据接收方提供对账查询接口（例如查从库）。

触发方式分2种：

- （**不推荐**）数据库变更事件触发：监听业务主表的binlog变更
- （**推荐**）业务消息触发：监听业务消息变更
> 推荐由业务消息触发，是因为数据库变更事件触发有局限：<br>
> - 如果有的写入操作**不更新业务主表**，比如**只更新了扩展表**，则需要新消费扩展表的binlog事件消息。
> - 如果**存在中间状态**，则需要等到记录变成终态后才能对账，需要过滤很多无效消息。

实现方案：

监听业务消息变更。业务消息需做成事务消息，即**业务操作完成必发出**(可以利用Spring提供的**事务钩子**)、不完成不发出。业务消息可以携带多个表的信息，能减少一定的查DB请求。
**延迟、批量消费**变更消息（如把增量订单id写入**redis的list**，下游批量拉取），然后批量查询本地DB数据、以及上下游接口。
最后逐个字段做比较。
![](/minio/weblog/945bced5910b46f290a4dfdc88e03f24.png)
>- 之所以要写入方发起对账，而不是接收方，是因为写入方调接收方的接口可能失败，接收方在写入失败时无法触发对账。
>- 之所以要延迟消费，是为了**避免短时间内的不一致造成误告警**（例如数据库主从延迟、接口超时重试等原因），比如延迟15秒再消费。
>- 之所以要积攒一批消息做批量消费，是为了**避免对账查询qps过高**，给本服务和上下游系统带来较大负载。
#### 离线对账（小时级到天级对账）
> 有了在线对账，为什么还需要离线对账呢？
> - 离线对账作为在线对账的兜底，可以定期跑历史存量数据
> - 离线对账不影响在线业务的稳定性
> - 外部第三方系统，一般**只能定期提供离线数据**，**无法提供对账查询接口**。典型的如第三方支付系统的对账单

实现方案：

- 离线采集：导出各系统的数据到hive表，可以是mysql表、或者是对账单
- 归一化数据：解析出所有的对账字段，**按统一格式生成新的宽表a、宽表b**
离线对比：<br>
（1）需要**比较条数**是否一致 <br>
（2）以及**数据内容**是否一致：通过左连接找到只存在于左表的数据，通过右连接找到只存在于右表的数据，通过内连接并比较各个字段来找到存在差异的数据
```SQL
-- （1）比较两个表的条数是否一致
select count(1) from table_a; -- 查出左表的条数
select count(1) from table_b; -- 查出右表的条数

-- （2）比较数据内容是否一致
-- （2.1）只存在于左表的数据：左连接查询，左表记录都会保留，右表字段为空则说明右表缺少数据：
select * from
table_a left outer join table_b
on table_a.biz_field=table_b.biz_field
where table_b.biz_field is null;

-- （2.2）只存在于右表的数据：右连接查询，右表记录都会保留，左表字段为空则说明左表缺少数据：
select * from
table_a right outer join table_b
on table_a.biz_field=table_b.biz_field
where table_a.biz_field is null;

-- （2.3）两个表存在差异的数据，内连接查询，比对各个字段是否一致：
select * from
table_a inner join table_b
on table_a.biz_field=table_b.biz_field
where
(table_a.field_1 <> table_b.field_1
or table_a.field_2 <> table_b.field_2
or table_a.field_3 <> table_b.field_3);

```
> 如果数据量比较小，可以借助redis的sdiff直接比较两个set的差集
####  修复
> - 如果是**条数不一致**可能是因为日切点导致的，可以放到差异表（需要二次对账）
> - 如果是**数据字段不一致**，需要放到异常表(告警/自动修复)
## 压测与灰度上线
- 分阶段压测
    -  压测准备：搭建**与生产环境一致**的测试环境，准备模拟数据（如不同渠道的订单数据、接口请求参数，这里最好使用**流量录制和回放**，模仿真实的数据）。
    -  压测场景与**指标**：分别测试常规流量、峰值流量、异常流量（如重复订单、畸形数据）场景，关注履约时效（目标 < 2 minute）、系统吞吐量、错误率（目标 < 0.1%）。
    -  **问题修复**：针对压测中出现的数据库慢查询、缓存命中低等问题，优化 SQL 语句、增加缓存预热机制等，修复后重新压测，直至满足指标要求。
- **灰度**上线与回滚预案
    -  灰度上线：先上线 10% 的第三方流量（如仅对接 A 渠道），观察系统运行指标，无异常后逐步扩大范围至 100% 流量。
    -  **针对核心高风险动作**：可以采用**延迟执行**的方式，获取到任务，先落表，观察是否无误再真正执行。
    -  回滚预案：提前准备回滚脚本，若上线后出现严重问题（如订单大面积解析失败），立即执行回滚，恢复至历史稳定版本；同时备份上线前的数据库数据，防止数据丢失。
 
