---
updateTime: '2026-01-22 14:20'
tags: Java
---
## 如何保证系统的可靠性？
> toc场景，非常重视**交付的可靠性**，甚至**大于交付的效率性**。所以，在整个研发声明周期过程中，要有 PRD(Product-Requirement-Document) 评审、研发设计代码、代码评审、代码分支合并评审，以及在这个过程中还有测试人员进行全流程的验证。<br>
> 但是通过线下环境测试识别风险，但可能因为**线下与线上数据存在差异**，以及**测试不够充分**，难以准确识别出所有潜在风险。<br>
> 所以可以通过录制在线流量、构建沙盒环境并执行流量回放，以**评估系统性能/准确性**。如**参数调优**、**慢查询优化**、**版本升级**等，那如何判断其变更后的效果和稳定性呢？
>
## 名词解释

- **录制**：把一次请求的入参、出参、下游RPC、DB、缓存等序列化并**存储**的过程
- **回放**：把录制数据还原，重新发起**一次或N次请求**，对特定的下游节点进行MOCK的过程
- **入口调用**：入口调用一般是应用的流量来源，比如http/dubbo/定时任务/MQ，在调用过程中录制调用入参，返回值。回放时作为流量发起和执行结果对比依据
- **子调用**：区别于入口调用，子调用是调用执行过程中某次方法调用。子调用在录制时会记录该方法的入参、返回值；回放时用该返回值进行MOCK
- **MOCK**：在回放时，被拦截的子调用不会发生真实调用，利用字节码动态干预能力，将录制时的返回值直接返回
- **降噪**：在回放时，部分回放子调用入参或者回放流量响应结果和原始流量对比不一致字段，对这些非必要字段进行排除对比过程

## 关键技术挑战与解决方案
<table border="1" cellpadding="6" cellspacing="0">
  <thead>
    <tr>
      <th style="background-color: #f5f5f5;">挑战</th>
      <th style="background-color: #f5f5f5;">解决方案</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>数据污染风险</td>
      <td>
        1. 敏感数据脱敏<br>
        2. 使用测试专用账户<br>
        3. 写操作重定向到mock服务
      </td>
    </tr>
    <tr>
      <td>时间敏感请求</td>
      <td>
        1. 移除时间戳参数<br>
        2. 使用相对时间处理<br>
        3. 重写时间相关header
      </td>
    </tr>
    <tr>
      <td>状态依赖问题</td>
      <td>
        1. 会话标识替换<br>
        2. 前置条件初始化<br>
        3. 事务链追踪
      </td>
    </tr>
    <tr>
      <td>外部依赖干扰</td>
      <td>
        1. 第三方服务mock<br>
        2. 请求重定向<br>
        3. 依赖服务录制回放
      </td>
    </tr>
  </tbody>
</table>


## 流量录制
> 流量录制，核心的本质就是把线上运行的应用，在有流量请求到服务接口后，把请求接口的**入参**和**执行的结果**，都保存下来。之后流量回放，则是把这些保存下来的入参信息，在开发环境/测试环境/预发环境，进行请求，之后**验证请求后的结果**是否与线上录制的流量结果一致。<br>
> 
> 但实际的操作场景要比这个过程复杂，如；录制流量的操作，要无侵入代码的，要把整个调用链路，全部录制下来，而不是单个接口。同时录制的不只是对接口的操作，还有缓存、rpc、数据库（MyBatis）、es，等各类组件兼容，都能确保可正确录制到完整数据，以便在流量回放时，可以mock掉数据接口，以此只验证功能逻辑。

### 实现方式

- ####  基于网络层的录制
工具示例：TCPCopy、GoReplay、mitmproxy

特点：
- 在TCP/IP层捕获原始网络包
- 无需应用代码修改
- 可能需处理加密流量

该方式只能抓取通过网络传输的原始数据报文，包括请求和响应的完整字节流。但由于工作在底层协议层，抓取到的内容可能包含**未解析的二进制数据或加密信息**（如 HTTPS 的 TLS 加密内容），需要额外进行协议解析（如 HTTP 协议解析）或解密处理才能提取出可读的业务数据。此外，对于经过特殊封装或私有协议的网络通信，抓取后的数据解析难度会显著增加，且可能因**网络层的分片、重传**等机制导致数据拼接复杂度提高。

- #### 基于应用层的录制
实现方案：
Java Servlet Filter示例
```java
public class TrafficRecorderFilter implements Filter {
    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) {
        // 记录请求
        CapturedRequest request = capture(req);
        chain.doFilter(req, res);
        // 记录响应
        request.setResponse(capture(res));
        storage.save(request);
    }
}
```
优点：可获取解密后的完整请求

- #### 基于Agent实现
> 为了可以**无侵入式的**完成系统的流量录制和流量回放，这里引入了一个 Java Agent 字节码增强(asm、javassist、byte-buddy)技术，通过在程序启动阶段，对工程代码的方法进行埋点。
> ![](/minio/weblog/480a403ad3d04225bb7c6a25c46aa8c1.png)
> ![](/minio/weblog/df391f76bce74b3f82e72fbb8ba02ed1.png)
- **ASM 动态代理**：直接拼接java 字节码， 调用 jdk api **defindClass生成代理类**。 虽然这种方式生成的代理类性能很好， 但是由于java 字节码语法复杂 容易出错，很少被使用。
- **javassist**动态代理原理总结：
与ASM 生成字节码的方式 不同，javassist 通过添加java代码 可以很方便的构建代理类，当添加了一段java格式源码，会通过 jdk api **Javac 编译**生成对应字节码，最后拼接成完整的类字节码，然后调用 jdk api defindClass生成代理类。
## 工具介绍
> 关于流量录制和流量回放的工具是蛮多的，其中包括；jvm-sandbox-repeater、MoonBox、arextest等。
>

![](/minio/weblog/edd59314ba3c4de9b45e41b09d071f52.png)


- jvm-sandbox-repeater，是一个基于 JVM-Sandbox 采用Java来实现的流量录制回放工具，或者可以理解为它是一个基于Java虚拟机的插件，可以直接运行中JVM中，无需对目标应用程序进行任何修改。
- Moonbox（月光宝盒），是一个无侵入的线上流量录制 和流量回放平台，沿用了jvm-sandbox-repeater的SPI设计，并提供了大量的常用插件，同时也提供数据统计和存储能力。通过Moonbox可以实现自动化测试、线上问题追踪、和业务监控等能力
- arextest，AREX 通过将**真实的在线流量复制到测试环境**进行自动化 API 测试来解决自动化测试的挑战。

## 字节内部ByteCopy
概述
ByteCopy 是流量复制工具，主要用于线上的流量进行复制、转发、存储，支持压测、Diff、流量数据分析等场景。
![](/minio/weblog/image_bytecopy.png)

核心能力
ByteCopy 提供两大核心能力：
1. 流量复制转发：将线上流量实时复制并转发到测试场景中的被测服务，用作测试流量（同步）；或将线上流量复制后写入用户提供的消息队列，供其他逻辑消费处理（异步）
2. 流量存储回放：通过 ByteCopy 提供的流量存储模块 Bluewhale 存储流量，可以回放到被测服务，或按照特定条件（如 Log ID、接口名称等）进行查询
业务流程
1. 流量录制流程
- 录制方式：
  - TCE 引流模式：默认只有 2 个业务 Pod 上采集，最大可设置 6-10 个实例
  - Mesh Proxy 模式：在每台业务 Pod 上都录制，单 Pod 最多录制流量是 5 QPS 每秒
  - Sniffer 模式：借助 ByteMesh 在实例中启动 Sniffer 进程嗅探网卡流量
2. 流量转发流程
- 支持将线上真实流量引入到多环境的实测服务中
- 支持节点压测（直接指定 IP 和 Port）和集群压测（通过服务信息）
- 流量放大倍数最大支持 16 倍
技术架构原理
![](/minio/weblog/image_bytecopy_2.png)
数据流向
![](/minio/weblog/image_bytecopy_3.png)
> eBPF能够捕获所有系统调用并监控一切，且性能卓越。开发者完全无需更改代码。
但是eBPF主要是捕获网卡的流量，好像不可以做到类似Java里angent探针这样，修改已经编译好的代码（能够捕获到方法的调用细节）
eBPF Dynamic Instrumentation
![](/minio/weblog/image_linux_call.png)
![](/minio/weblog/image_linux_arch.png)
1. 采集层技术
ByteCopy 支持多种流量采集技术：

| 采集方式 | 技术原理 | 适用场景 |
| --- | --- | --- |
| TCE 引流 | 在指定实例上部署采集代理 | 高 QPS 场景，需要稳定流量 |
| Mesh Proxy | 基于 ByteProxy 实现流量录制机制 | 分布式采集，低 QPS 场景 |
| Sniffer | 嗅探网卡流量并解析为原始请求 | 无需开启入流量代理的场景 |
2. 存储架构
- Bluewhale：主要存储介质，支持 HTTP 协议和部分 Thrift 协议流量
- HDFS：存储包含 Thrift 数据筛选或多索引的任务
- IndexService：存储包含下游筛选的 Thrift 流量工厂任务
3. 性能特性
- 资源开销：TCE 引流模式通常占用单实例 0.5C/1.5GB 
- Mesh Proxy 模式：在 1k QPS 场景下的开销为 0.32C 
- 数据有效期：录制的数据有效期为 14 天

## 案例
未完待续...


