> 介绍从基于规则的 到机器学习的 到深度学习的 到生成式的 推荐系统总结

## 简洁系统的推荐(基于规则的推荐)
![](/minio/weblog/3633b0de05be4e87a1d663fe103ff301.png)
> 如果每次都随机给用户推荐物品，则无法将平台/独特的优质物品展现出来。例如在商城系统中，可以根据用户的收藏数、评论数、销量等数据对内容进行排序，**按倒序依次推荐**给用户。此外，还可以设置一个**运营池**和**热点池**，由运营人员在后台进行手动更新，确保实时热点展示。
![](/minio/weblog/4cf736f5ce1f4f1d85a692721c35b934.png)

## 机器学习推荐
### 逻辑回归

   - 核心原理：假设特征之间相互独立，通过 sigmoid 函数将特征线性组合映射为 0-1 概率（预测用户是否喜欢某物品），本质是「**二分类任务**」的推荐召回 / 排序模型。
   - 优点：模型简单、训练速度快、可解释性强（能量化每个特征的权重）；
   - 缺点：无法捕捉特征间的交互关系（如 “年轻女性 + 喜欢美妆” 的组合兴趣），表达能力有限。
   - 应用场景：推荐系统的召回 / 排序阶段（作为**基准模型**），尤其适用于数据稀疏场景。
![](/minio/weblog/da8849356389450f9db454876d9e549c.png)

> 逻辑回归 需要**假设特征之间相互独立**，通过生成0-1之间的概率值预测是否召回

### 多项式回归
   - 核心原理：在线性回归基础上**引入特征的高阶项**（如 x²、x³），拟合用户行为与物品属性的**非线性关系**（如 “用户浏览时长与购买概率的二次关系”）。
   - 优点：相比线性回归，能捕捉简单非线性模式；
   - 缺点：需提前假设高阶项次数，泛化能力弱，易过拟合（高阶项对噪声敏感）。
   - 应用场景：特征交互简单、可解释性要求高的排序场景。
> 多项式回归 需要提前假设最高阶

### 协同过滤
> 首次实现「不依赖物品 / 用户属性，仅通过行为数据挖掘关联」，核心思想是「**物以类聚，人以群分**」。

  ![](/minio/weblog/6f1865d420604472a10d3f8cfac6b250.png)

  - UserCF
    -  > 一句话总结，A买了苹果，B和A相似，B可能也会买苹果（**横着**计算相似度）
  ![](/minio/weblog/1b359e5567924c73a947ad484c1c9f6d.png)![](/minio/weblog/a97a2296cbfe4185bc0442367bf5389f.png)
相似度计算：皮尔逊相关系数、余弦相似度、Jaccard 相似度。
       > - 优点：能捕捉用户群体兴趣，适用于社交属性强的场景（如朋友圈推荐）；
       > - 缺点：用户相似度计算复杂度高（O (N²)，**N 为用户数**），稀疏用户（行为少）的相似度不可靠，易受热门物品影响。
  - ItemCF
    -  > 一句话总结，A买了苹果，苹果和橘子相似，A可能也会买橘子(**竖着**计算相似度)
       > ![](/minio/weblog/8dde55dd21d2417687ecd1b3e521e292.png)
       > - 优点：物品相似度相对稳定（更新频率低于用户），计算复杂度低（O (M²)，**M 为物品数**），推荐结果解释性强（“基于你喜欢的 X 推荐”）；
       > - 缺点：对新物品不友好（无行为数据则无法计算相似度），易推荐同质化物品（如买了手机推荐手机壳，**无法挖掘跨品类兴趣**）。
## 矩阵分解（CF 的改进）

> CF 模型无法处理「用户 - 物品交互矩阵」的**稀疏性**（大部分用户未接触过大部分物品）。
![](/minio/weblog/1dc1247a6e424c24a8bbc9f6e848e153.png)

- 核心原理：将用户 - 物品交互矩阵（N×M）分解为「**用户隐向量矩阵**」（N×K）和「**物品隐向量矩阵**」（M×K），其中 K 是隐因子维度（代表用户 / 物品的潜在特征，如 “喜欢运动”“偏性价比”）。<br>
  用户对物品的评分 / 点击概率 = 用户隐向量・物品隐向量（内积）。

- 优点：能挖掘用户潜在兴趣，解决数据稀疏问题，可解释性（隐因子可映射为实际语义，如 “标签喜好程度 × 物品标签含量”）；
- 缺点：对冷启动物品 / 用户仍不友好，无法融入外部特征（如用户年龄、物品类别）。
## 特征交互建模：FM 与 DeepFM
> LR 无法捕捉特征交互，CF (**基于打分**)无法融入多类型特征（如用户属性、物品属性、场景特征）<br>
> 我们希望 score=用户对某个标签的喜好程度 * 这个物品包含这个标签的含量（用户的特征 * 物品特征）
###  FM（Factorization Machine）
   - 核心原理：**对每个特征训练一个隐因子向量**，通过隐向量内积建模特征间的二阶交互（如 “用户年龄 = 25”×“物品类别 = 运动”），公式如下：
   ![](/minio/weblog/dde631c678ce4b37ba6b8831863269fd.png)
   - 优点：能高效建模**二阶特征交互**，解决稀疏数据下的特征交互学习问题，可融入多类型特征；
   - 缺点：无法捕捉高阶非线性交互，表达能力有限。
### DeepFM（Deep Factorization Machine）
   - 核心原理：结合 FM 和深度学习的优势，FM 部分建模二阶特征交互，DNN 部分建模**高阶非线性交互**，无需人工设计特征交互，实现「**端到端**的特征交互学习」
   - 优点：同时捕捉低阶和高阶特征交互，自动化特征工程，适用于高维稀疏数据（推荐系统典型场景）；
   - 缺点：模型复杂度高于 FM，训练成本较高，需调参优化（如隐层维度、学习率）。
## 深度学习推荐
> 深度学习的引入彻底打破了传统机器学习的「**特征工程依赖**」和「**表达能力上限**」，通过神经网络自动学习复杂的非线性关系和高阶特征交互
### 双塔模型
- 核心设计思想：将「**用户特征**」和「**物品特征**」分别通过两个独立的神经网络（用户塔、物品塔）映射到**同一隐空间**，推荐得分 = 用户隐向量・物品隐向量（内积）
![](/minio/weblog/e6975e132816482cb1567c81ef4a2976.png)

- 核心结构：
   - **用户塔**：输入用户特征（如年龄、性别、历史行为序列），通过 Embedding+FCNN 将用户映射为固定维度的隐向量；
   - **物品塔**：输入物品特征（如类别、价格、标签），通过 Embedding+FCNN 将物品映射为固定维度的隐向量；
   - 匹配层：计算**两个隐向量的相似度**（内积、余弦相似度），作为推荐分数。

- 优点：
   - 分离用户和物品的特征学习，可分别离线预计算用户 / 物品隐向量，**在线推理时仅需计算相似度**， latency 极低（适用于高并发场景）；
   - 支持大规模候选集召回（如亿级物品库中快速匹配用户兴趣）；
   - 能融入丰富的用户 / 物品特征，表达能力强。
- 缺点：
   - 双塔结构的独立性导致无法捕捉用户 - 物品的细粒度交互（如 “用户喜欢红色且物品是红色” 的强交互）；
   - **隐向量维度选择对效果影响较大**。
### 其他深度学习模型
- **序列推荐**模型：如 GRU4Rec、NCF（Neural Collaborative Filtering），专注于捕捉用户行为序列的时序依赖（如 “用户先看手机，再看手机壳，接着看充电器” 的连贯兴趣）；
- **多任务学习**模型：如 MMoE（Mixture of Experts），同时优化多个推荐目标（如点击、收藏、购买），提升模型的综合效果；
- **图神经网络**（GNN）推荐：如 NGCF、LightGCN，将用户 - 物品交互建模为图结构，通过图卷积传播兴趣，挖掘更复杂的关联关系（如 “用户 A 喜欢物品 X，物品 X 与物品 Y 相关，用户 B 喜欢物品 Y，推荐 X 给 B”）。
## 生成式推荐
> 随着大语言模型（LLM）的爆发，推荐系统进入「**生成式**」时代。传统推荐系统是「从现有物品中筛选匹配」，而生成式推荐是「直接生成用户可能喜欢的物品（或物品序列）」，核心基于 Transformer 架构。
![](/minio/weblog/f589b13758a94b2a97160441e2b64e9e.png)

- 基于 Transformer 的 Decoder 结构（如 GPT 系列），将推荐任务转化为「序列生成任务」：
  - 输入：用户历史**行为序列**（如 “用户 A 点击了物品 X→收藏了物品 Y→购买了物品 Z”）；
  - 输出：用户**下一个可能交互的物品序列**（如 “物品 W→物品 V”）。
- 核心逻辑：通过 Transformer 的自注意力机制，**捕捉用户行为的长程依赖**和语义关联（如 “购买跑步机”→“推荐瑜伽垫” 的逻辑关联），直接生成推荐列表，而非从现有物品库中筛选。