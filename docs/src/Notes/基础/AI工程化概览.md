---
updateTime: '2025-12-21 18:26'
tags: 基础
---
## AI能帮我们做什么？
- 意图识别？
- 数据分析？
- 参数抽取？
- 流程自动化？


## RAG
> 由于大模型的训练数据是使用通用的的知识，他并不包含**垂直领域的知识**，所以可以通过给大模型外挂一些知识库，通过**相似度检索**的方式，和用户的promt一起发送给大模型，让他**基于召回的上下文**回答问题
>
- 难点
  - 召回topk，**k值**如何确定？如果没有召回成功？
    - SelfCheck机制：**让LLM先评估召回文档**是否足以回答问题，若不足则**触发关键词扩展**或**二次检索**
    - 引导用户 / prompt改写(**hyde假设性文档嵌入**) / few short、思维链
  - 如何判断/检测**召回**的知识是对的，使用什么**指标**来判断？
    - 召回层（Precision@K, Recall@K,F1）
      - Precision@K = （Top K 中相关结果数） / K
        - > 衡量召回结果的 **“准确性”**，避免返回大量无关内容
      - Recall@K = （Top K 中相关结果数） / （知识库中所有相关结果数）
        - > 衡量召回结果的 **“全面性”**，避免遗漏重要相关内容。
      - F1 = 2 *(Precision * Recall) / (Precision + Recall)
        -  > F1 分数是精确率和召回率的**调和平均数**，而非简单算术平均。调和平均数的特性是，只有当精确率和召回率两者都较高时，F1 分数才会高；
      - 构建黄金测试集，**对召回文本打分**
    - 生成层（上下文利用率、答案忠实度(Faithfulness)）
      - 让大模型打分：“生成的答案是否**被召回文档完全支持**？”
  - 如果知识库非常大，如何**加速召回数据**？
    - Flat(O(n))
    - IVF（Inverted File Index，倒排文件索引）
      - 先找到聚类中心，再在**聚类中心搜索**
    - ANN近似最近邻
      - HNSW分层导航小世界图
  - 使用什么**分块策略**，保证召回的知识不是零散的？
    - 语义(embadding)
    - 长度/段落
    - 文档结构感知(Dom感知)
    - 滑动窗口
    - 知识图谱
      - 实体抽取(LLM/命名实体识别) → 构建(实体-关系-实体)三元组
      -  对**关系子图**生成摘要向量（而非原文chunk）
      -  检索阶段：
         - Query → 意图识别 → 图谱子图召回 → 子图关联原文
## MCP
> 由于大模型只能充当一个大脑，他**不具备调用工具/打开使用资源的能力**，你就可以利用大模型的**意图识别的能力**来调用外部的工具，但是怎么调用，我们的应用的系统怎么知道什么时候调用？所以提供一个**通用的规范**，让其知道什么时候调用
- 协议
  -  采用JSON-RPC2.0协议
      -  请求
      > 规定请求对象必须包含以下字段
      > 
      > - jsonrpc：协议版本，固定为 "2.0"。
      > - method：要调用的方法名称。
      > - params：方法的参数，可以是任意 JSON 格式的数据。
      > - id：请求的唯一标识符，用于匹配响应。
      -  响应（Response）
      > 规定请求对象必须包含以下字段
      > - jsonrpc：协议版本，固定为 "2.0"。
      > - id：与请求中的 id 相匹配。
      > - result：操作的结果数据（如果成功）。
      > - error：错误信息（如果失败），包含 code 和 message 字段。
  - 端点
    - **HTTP POST 端点**：用于客户端向服务器**调用工具**。

    - **SSE 端点**：用于给客户端建立连接，给他推送 获取工具的url（告诉他哪个url具有什么功能，然后它通过post请求来获取）

    - Http Stream (Flux)
    > 增加响应头：<br>
    > Transfer-Encoding: chunked（分块编码）<br>
    > Connection: keep-alive（保持连接）<br>
    > 不指定 Content-Length <br>
    > 注意实时不要缓存Cache-Control: no-cache<br>
## Function Call
> 工具调用，以**promt的方式**(userMessage/systemMessage)告诉大模型，我有哪些工具可以使用，大模型返回需要调用的函数名称，参数是什么，在java代码层面就可以以**反射的方式去调用方法**。
>
## ReActAgent
> 一个agent由**大模型、工具、资源**共同组成。
> **以ReActAgent为例**，分为Reasoning(thought),action,observation,final answer <br>
> 1. 大模型先思考(thought),判断是否调用工具
> 2. 调用工具(action) 
> 3. 观察结果，如果不满足需求，继续回到1
> 4. 如果满足结果，返回fianl answer
## Mutil Agent
> 如果任务比较庞大，避免上下文爆炸，可以给**不同的Agent划分不同的职责** <br>
> 例如，可以分为**PlanAgent专门做任务拆解**，给出执行计划 <br>
> planAgent和其它Agent交互，**把任务分配给不同的Agent执行**，最后验收结果(也可以有专门的验收Agent)
>
## Memory工程
> 由于和大模型的交互是无状态的，大模型不知道用户上一次提问了什么问题，所以需要我们自己把**历史对话**一起交给大模型。
> - 问题1：大模型能接受的token(上下文窗口)是有限的，不能把所有历史记忆都丢给大模型，所以需要选当前对话窗口内的对话一起发给大模型
> - 问题2：窗口选多少合适？不确定，所以有一个context engineer的概念，
>   - 可以通过大模型的方式，对历史对话进行**总结和压缩**；
>   - 或者 将用户的历史记录进行embadding 根据**相似度召回 相关的聊天记录**
>
## 调用监控和权限
> 不能让用户无线提问重复/恶意调用我们的大模型，浪费我们的token,所以需要对**入口进行监控**<br>
> 对于**工具/资源**，需要做好权限校验，不能随意调用<br>
> 还可以把用户**常用的问题和答案缓存起来**，避免大量重复调用。
> 难点：由于用户的对同一个问题的问法随机，缓存key非常难设计 <br>
>   可以设计聚类中心,把用户的promt归为某**一个聚类中心**
